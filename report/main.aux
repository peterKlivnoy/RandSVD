\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{halko2011finding}
\citation{liberty2007randomized,rokhlin2010randomized}
\citation{martinsson2020randomized}
\citation{clarkson2017low,woodruff2014sketching}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{3}{section.1}\protected@file@percent }
\newlabel{sec:intro}{{1}{3}{Introduction}{section.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}The Core Algorithmic Framework}{3}{subsection.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Research Questions and Contributions}{3}{subsection.1.2}\protected@file@percent }
\citation{halko2011finding}
\citation{halko2011finding}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Randomized SVD with Power Iterations \citep  {halko2011finding}}}{4}{algorithm.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{alg:randsvd}{{1}{4}{Randomized SVD with Power Iterations \citep {halko2011finding}}{algorithm.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Theoretical Background}{4}{section.2}\protected@file@percent }
\newlabel{sec:background}{{2}{4}{Theoretical Background}{section.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}The Randomized Range Finder}{4}{subsection.2.1}\protected@file@percent }
\citation{halko2011finding}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Sketching Matrix Constructions}{5}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Gaussian Random Matrices.}{5}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Subsampled Randomized Fourier Transform (SRFT).}{5}{section*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Subsampled Randomized Hadamard Transform (SRHT).}{5}{section*.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{CountSketch (Sparse Embeddings).}{5}{section*.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Theoretical Accuracy Guarantees}{5}{subsection.2.3}\protected@file@percent }
\newlabel{thm:expected}{{1}{5}{Expected Error Bound}{theorem.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Complexity Summary}{6}{subsection.2.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Computational complexity and characteristics of sketching methods for $A \in \mathbb  {R}^{m \times n}$ with sketch size $\ell $.}}{6}{table.caption.6}\protected@file@percent }
\newlabel{tab:complexity}{{1}{6}{Computational complexity and characteristics of sketching methods for $A \in \R ^{m \times n}$ with sketch size $\ell $}{table.caption.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Implementation}{6}{section.3}\protected@file@percent }
\newlabel{sec:implementation}{{3}{6}{Implementation}{section.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Optimized Implementations}{6}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Naive Pure-Python Implementations}{7}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4}Experimental Methodology}{7}{section.4}\protected@file@percent }
\newlabel{sec:setup}{{4}{7}{Experimental Methodology}{section.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Test Matrix Construction}{7}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Parameter Settings}{7}{subsection.4.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Evaluation Metrics}{7}{subsection.4.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Comparison of full SVD versus randomized SVD (Gaussian, $k=20$, $p=10$, $q=1$) across matrix dimensions. Panel (a) shows absolute computation time on a log-log scale, with extrapolated full SVD times (dashed) for the largest matrices where full computation was not performed. Panel (b) shows the speedup factor achieved by randomized SVD. Panel (c) shows the error ratio relative to the optimal rank-$k$ approximation, confirming that accuracy remains near-optimal despite the dramatic speedup.}}{8}{figure.caption.7}\protected@file@percent }
\newlabel{fig:motivation}{{1}{8}{Comparison of full SVD versus randomized SVD (Gaussian, $k=20$, $p=10$, $q=1$) across matrix dimensions. Panel (a) shows absolute computation time on a log-log scale, with extrapolated full SVD times (dashed) for the largest matrices where full computation was not performed. Panel (b) shows the speedup factor achieved by randomized SVD. Panel (c) shows the error ratio relative to the optimal rank-$k$ approximation, confirming that accuracy remains near-optimal despite the dramatic speedup}{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Hardware and Software Environment}{8}{subsection.4.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5}The Fundamental Advantage: RandSVD versus Full SVD}{8}{section.5}\protected@file@percent }
\newlabel{sec:motivation}{{5}{8}{The Fundamental Advantage: RandSVD versus Full SVD}{section.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Sketching Method Comparison on Dense Matrices}{8}{section.6}\protected@file@percent }
\newlabel{sec:dense}{{6}{8}{Sketching Method Comparison on Dense Matrices}{section.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Speed comparison of sketching methods on dense matrices. Panel (a) shows optimized implementations on a $2048 \times 2048$ matrix, with full SVD time (1496ms) shown as a reference line and complete RandSVD time shown separately. Panel (b) shows naive pure-Python implementations on a smaller $512 \times 512$ matrix, revealing the true algorithmic complexity differences. Panel (c) shows speedup factors of structured methods relative to Gaussian.}}{9}{figure.caption.8}\protected@file@percent }
\newlabel{fig:dense}{{2}{9}{Speed comparison of sketching methods on dense matrices. Panel (a) shows optimized implementations on a $2048 \times 2048$ matrix, with full SVD time (1496ms) shown as a reference line and complete RandSVD time shown separately. Panel (b) shows naive pure-Python implementations on a smaller $512 \times 512$ matrix, revealing the true algorithmic complexity differences. Panel (c) shows speedup factors of structured methods relative to Gaussian}{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Optimized Implementations}{9}{subsection.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Revealing True Complexity: Naive Implementations}{9}{subsection.6.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Speed comparison on sparse matrices ($4000 \times 4000$). Panel (a) shows absolute timing across density levels. CountSketch time scales linearly with density (number of nonzeros), while Gaussian time remains approximately constant regardless of sparsity. Panel (b) shows the speedup factor achieved by CountSketch, reaching over 100$\times $ at 0.1\% density. Panel (c) confirms that both methods achieve similar approximation accuracy.}}{10}{figure.caption.9}\protected@file@percent }
\newlabel{fig:sparse}{{3}{10}{Speed comparison on sparse matrices ($4000 \times 4000$). Panel (a) shows absolute timing across density levels. CountSketch time scales linearly with density (number of nonzeros), while Gaussian time remains approximately constant regardless of sparsity. Panel (b) shows the speedup factor achieved by CountSketch, reaching over 100$\times $ at 0.1\% density. Panel (c) confirms that both methods achieve similar approximation accuracy}{figure.caption.9}{}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Sparse Matrix Experiments: The CountSketch Advantage}{10}{section.7}\protected@file@percent }
\newlabel{sec:sparse}{{7}{10}{Sparse Matrix Experiments: The CountSketch Advantage}{section.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Optimized Sparse Sketching}{10}{subsection.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Algorithmic Complexity Analysis}{10}{subsection.7.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Accuracy analysis. Panel (a) compares approximation error across sketching methods and spectral decay profiles, showing that all methods achieve similar accuracy. Panel (b) shows the dramatic effect of power iterations on slowly decaying spectra. Panel (c) shows the effect of oversampling parameter $p$, demonstrating diminishing returns beyond $p \approx 10$.}}{11}{figure.caption.10}\protected@file@percent }
\newlabel{fig:accuracy}{{4}{11}{Accuracy analysis. Panel (a) compares approximation error across sketching methods and spectral decay profiles, showing that all methods achieve similar accuracy. Panel (b) shows the dramatic effect of power iterations on slowly decaying spectra. Panel (c) shows the effect of oversampling parameter $p$, demonstrating diminishing returns beyond $p \approx 10$}{figure.caption.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.3}Naive Comparison}{11}{subsection.7.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {8}Accuracy Analysis}{11}{section.8}\protected@file@percent }
\newlabel{sec:accuracy}{{8}{11}{Accuracy Analysis}{section.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1}Sketching Method Comparison}{11}{subsection.8.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.2}The Critical Role of Power Iterations}{11}{subsection.8.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {8.3}Effect of Oversampling}{12}{subsection.8.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9}Robustness to Data Perturbations}{12}{section.9}\protected@file@percent }
\newlabel{sec:robustness}{{9}{12}{Robustness to Data Perturbations}{section.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1}Experimental Setup}{12}{subsection.9.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2}Additive Gaussian Noise}{12}{subsection.9.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Robustness analysis. Panel (a) shows reconstruction error versus noise level for different numbers of power iterations, revealing that high $q$ can hurt at high noise. Panel (b) shows graceful degradation with missing entries. Panel (c) demonstrates vulnerability to outliers---even 1\% corrupted entries significantly impact accuracy.}}{13}{figure.caption.11}\protected@file@percent }
\newlabel{fig:robustness}{{5}{13}{Robustness analysis. Panel (a) shows reconstruction error versus noise level for different numbers of power iterations, revealing that high $q$ can hurt at high noise. Panel (b) shows graceful degradation with missing entries. Panel (c) demonstrates vulnerability to outliers---even 1\% corrupted entries significantly impact accuracy}{figure.caption.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.3}Missing Entries}{13}{subsection.9.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.4}Sparse Outliers}{13}{subsection.9.4}\protected@file@percent }
\citation{musco2015randomized}
\citation{musco2015randomized}
\citation{musco2015randomized}
\citation{musco2015randomized}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces Block Krylov SVD}}{14}{algorithm.2}\protected@file@percent }
\newlabel{alg:krylov}{{2}{14}{Block Krylov SVD}{algorithm.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {10}Advanced Iterative Methods: Block Krylov}{14}{section.10}\protected@file@percent }
\newlabel{sec:krylov}{{10}{14}{Advanced Iterative Methods: Block Krylov}{section.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.1}The Block Krylov Subspace}{14}{subsection.10.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.2}Comparison with Simultaneous Iteration}{14}{subsection.10.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.3}Experimental Comparison}{14}{subsection.10.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Comparison of simultaneous iteration vs block Krylov using the three metrics from \citet  {musco2015randomized}. Rows show Frobenius (weak), spectral (strong), and per-vector (strongest) errors. Columns show different spectral decay rates (smaller = heavier tail). Block Krylov shows modest improvement on the weak metric but dramatic improvement on the strong metrics, validating the paper's theoretical predictions.}}{15}{figure.caption.12}\protected@file@percent }
\newlabel{fig:krylov}{{6}{15}{Comparison of simultaneous iteration vs block Krylov using the three metrics from \citet {musco2015randomized}. Rows show Frobenius (weak), spectral (strong), and per-vector (strongest) errors. Columns show different spectral decay rates (smaller = heavier tail). Block Krylov shows modest improvement on the weak metric but dramatic improvement on the strong metrics, validating the paper's theoretical predictions}{figure.caption.12}{}}
\@writefile{toc}{\contentsline {paragraph}{Frobenius error (weak).}{15}{section*.13}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Spectral error (strong).}{15}{section*.14}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Per-vector error (strongest).}{15}{section*.15}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Gap independence.}{15}{section*.16}\protected@file@percent }
\citation{musco2015randomized}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.4}Computational Considerations}{16}{subsection.10.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {10.5}When to Use Block Krylov}{16}{subsection.10.5}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {11}Synthesis and Practical Recommendations}{16}{section.11}\protected@file@percent }
\newlabel{sec:synthesis}{{11}{16}{Synthesis and Practical Recommendations}{section.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {11.1}Summary of Findings}{16}{subsection.11.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {11.2}Practical Recommendations}{16}{subsection.11.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Comprehensive summary. Panel (a) shows time scaling with matrix dimension for different sketching methods. Panel (b) shows the sparse versus dense comparison across density levels. Panel (c) summarizes the accuracy characteristics, confirming that all methods achieve similar quality with appropriate parameter choices.}}{17}{figure.caption.17}\protected@file@percent }
\newlabel{fig:summary}{{7}{17}{Comprehensive summary. Panel (a) shows time scaling with matrix dimension for different sketching methods. Panel (b) shows the sparse versus dense comparison across density levels. Panel (c) summarizes the accuracy characteristics, confirming that all methods achieve similar quality with appropriate parameter choices}{figure.caption.17}{}}
\@writefile{toc}{\contentsline {section}{\numberline {12}Conclusion}{17}{section.12}\protected@file@percent }
\newlabel{sec:conclusion}{{12}{17}{Conclusion}{section.12}{}}
\citation{musco2015randomized}
\bibstyle{plainnat}
\bibcite{halko2011finding}{{1}{2011}{{Halko et al.}}{{}}}
\bibcite{liberty2007randomized}{{2}{2007}{{Liberty et al.}}{{}}}
\bibcite{martinsson2020randomized}{{3}{2020}{{Martinsson \& Tropp}}{{}}}
\bibcite{woodruff2014sketching}{{4}{2014}{{Woodruff}}{{}}}
\bibcite{tropp2011improved}{{5}{2011}{{Tropp}}{{}}}
\bibcite{clarkson2017low}{{6}{2017}{{Clarkson \& Woodruff}}{{}}}
\bibcite{rokhlin2010randomized}{{7}{2010}{{Rokhlin et al.}}{{}}}
\bibcite{musco2015randomized}{{8}{2015}{{Musco \& Musco}}{{}}}
\bibcite{saibaba2019randomized}{{9}{2019}{{Saibaba}}{{}}}
\bibcite{achlioptas2003database}{{10}{2003}{{Achlioptas}}{{}}}
\bibcite{candes2011robust}{{11}{2011}{{Cand\`{e}s et al.}}{{}}}
\bibcite{tropp2017practical}{{12}{2017}{{Tropp et al.}}{{}}}
\gdef \@abspage@last{19}
